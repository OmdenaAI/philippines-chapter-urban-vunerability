{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbhe5E2Qcwcb"
      },
      "source": [
        "Before running the script make sure you have added a shortcut to the [NOAH Datasets](https://drive.google.com/drive/folders/1ALE4-E9c-4AGjm1fqiPprWHrLUskeY9o?usp=share_link) into your Google Drive..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDwd_vdpfjLb",
        "outputId": "231f59fc-f9af-43b4-b120-11f0a7bdbc73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount data from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuYhbi2Ls0Ik"
      },
      "source": [
        "*Making a copy of NOAH dataset on Google Drive.* First, `cd` into the NOAH dataset shortcut by running the cell below. The path to it might differ for you but in my case I added it into my GDrive's root folder. \n",
        "\n",
        "The format for the command is: \n",
        "\n",
        "\n",
        "```\n",
        "%cd /path/to/NOAH/shortcut\n",
        "```\n",
        "\n",
        "Upon running, it should show the exact path to the symbolic link. Copy it! Mine looks like this: \n",
        "\n",
        "`/content/drive/.shortcut-targets-by-id/1ALE4-E9c-4AGjm1fqiPprWHrLUskeY9o/NOAH Downloads`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a8jbB2aeiLG",
        "outputId": "e6354b19-d1f9-452b-bff1-196bec90102f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1ALE4-E9c-4AGjm1fqiPprWHrLUskeY9o/NOAH Downloads\n"
          ]
        }
      ],
      "source": [
        "#%cd /content/drive/MyDrive/NOAH Downloads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKNuAsk-hBdM"
      },
      "source": [
        "Next, create a new folder in your Google Drive where we will copy the contents of the NOAH dataset to. Mine is in the path: \n",
        "\n",
        "`/content/drive/MyDrive/noah`\n",
        "\n",
        "(I don't use Colab that much so I don't mind cluttering up my root folder lol)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WAr1rBDdY8M"
      },
      "source": [
        "Run the cell below to copy from the shortcut into your desired destination folder. This has to be done because files inside shortcuts are read-only. \n",
        "\n",
        "`cp -r '/sym/link/path/.' 'path/to/desired/directory'`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bzaoVm5Je1GL"
      },
      "outputs": [],
      "source": [
        "#%cp -r '/content/drive/.shortcut-targets-by-id/1ALE4-E9c-4AGjm1fqiPprWHrLUskeY9o/NOAH Downloads/.' '/content/drive/MyDrive/noah'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax6ZWfvXh0ld"
      },
      "source": [
        "Lastly, under your desired category, copy the contents of the ph_cities_v2 folder from our repo. \n",
        "\n",
        "The path in the repo is this: \n",
        "\n",
        "`philippines-chapter-urban-vunerability/src/data/geolocation/ph_cities_joined_v2/`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Z6yJJtPhbvb6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import shutil\n",
        "import geopandas as gp\n",
        "import os\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_01k-8Wc6Yr"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fFSTwcZz3ybT"
      },
      "outputs": [],
      "source": [
        "def unzip_path(path):\n",
        "  zipfile.ZipFile(path).extractall(temp_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ruYYN7VU4l5N"
      },
      "outputs": [],
      "source": [
        "def delete_zip_folder():\n",
        "  for filename in os.listdir(temp_folder):\n",
        "    file_path = os.path.join(temp_folder, filename)\n",
        "    try:\n",
        "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "            os.unlink(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            shutil.rmtree(file_path)\n",
        "    except Exception as e:\n",
        "        print('Failed to delete %s. Reason: %s' % (file_path, e))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xSz7A1J47iTp"
      },
      "outputs": [],
      "source": [
        "def map_to_city(path_to_dir, dirs):\n",
        "  for dir in dirs:\n",
        "    print(f\"Merging {dir}...\")\n",
        "    path = Path(path_to_dir, dir)\n",
        "    zip_files = os.listdir(path)\n",
        "\n",
        "    for i in range(len(zip_files)): \n",
        "\n",
        "      print(f\"Progress: {i+1}/{len(zip_files)}\")\n",
        "\n",
        "      print(f\"Unzipping {zip_files[i]}...\")\n",
        "      unzip_path(Path(path, zip_files[i]))\n",
        "\n",
        "      print(f\"Reading {zip_files[i]}...\")\n",
        "      if i == 0:\n",
        "        gdf = gp.read_file(Path(path,zip_files[i]))\n",
        "        dissolve_col = [col for col in gdf.columns if col != \"geometry\"][0]\n",
        "      else:\n",
        "        temp_gdf = gp.read_file(Path(path,zip_files[i]))\n",
        "        gdf = pd.concat([gdf, temp_gdf])\n",
        "\n",
        "        # Dissolving in HAZ\n",
        "\n",
        "        gdf = gdf.dissolve(by=dissolve_col, aggfunc=\"sum\")\n",
        "        gdf = gdf.reset_index()\n",
        "\n",
        "      print(f\"Deleting {zip_files[i]} artifacts...\")\n",
        "      delete_zip_folder()\n",
        "      print(\"========\")\n",
        "\n",
        "    destination_dir = Path(path, f\"{dir}-merged\")\n",
        "    destination_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    gdf.to_parquet(Path(destination_dir, f\"{dir}.parquet\"))\n",
        "\n",
        "    merged = gp.overlay(df, gdf, how='intersection').reset_index()\n",
        "    merged.to_parquet(Path(destination_dir, f\"{dir}-by-city-munic.parquet\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fcfDXJK_vPG-"
      },
      "outputs": [],
      "source": [
        "# Create temp_folder to hold unarchived zip-files\n",
        "temp_folder = Path(\"/content/drive/MyDrive/temp-folder\")\n",
        "temp_folder.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mU8ULvU2GC_T"
      },
      "outputs": [],
      "source": [
        "# Import city/municipality df\n",
        "# This is the path to the shp file in the \n",
        "# ph_cities_joined_v2 we pasted earlier. \n",
        "df = gp.read_file(\"/content/drive/MyDrive/noah/ph_cities_joined_v2/ph_cities_v2.shp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hL9xq4abLRKT"
      },
      "outputs": [],
      "source": [
        "keep_cols = [\"name\", \"geometry\"]\n",
        "df = df[keep_cols]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRG0Uf6yc_km"
      },
      "source": [
        "## Storm Surge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4e_QY_XAxGD1"
      },
      "outputs": [],
      "source": [
        "PATH_TO_STORMSURGE_DIR = Path(\"/content/drive/MyDrive/noah/Storm Surge\")\n",
        "storm_surge_advisory_dirs = [f\"StormSurgeAdvisory{i}\" for i in np.arange(1,5)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qSrqZbBACH1",
        "outputId": "2a8a2151-15e9-4d11-ffbf-b217190ec527"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Merging StormSurgeAdvisory1...\n",
            "Progress: 1/68\n",
            "Unzipping Zambales.zip...\n",
            "Reading Zambales.zip...\n",
            "Deleting Zambales.zip artifacts...\n",
            "========\n",
            "Progress: 2/68\n",
            "Unzipping CamarinesSur.zip...\n",
            "Reading CamarinesSur.zip...\n",
            "Deleting CamarinesSur.zip artifacts...\n",
            "========\n",
            "Progress: 3/68\n",
            "Unzipping Quezon.zip...\n",
            "Reading Quezon.zip...\n",
            "Deleting Quezon.zip artifacts...\n",
            "========\n",
            "Progress: 4/68\n",
            "Unzipping Aurora.zip...\n",
            "Reading Aurora.zip...\n",
            "Deleting Aurora.zip artifacts...\n",
            "========\n",
            "Progress: 5/68\n",
            "Unzipping Batanes.zip...\n",
            "Reading Batanes.zip...\n"
          ]
        }
      ],
      "source": [
        "map_to_city(PATH_TO_STORMSURGE_DIR, storm_surge_advisory_dirs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HywLf_72APuN"
      },
      "source": [
        "## Flood"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "N5ShLLyMAUA6"
      },
      "outputs": [],
      "source": [
        "PATH_TO_FLOOD_DIR = Path(\"/content/drive/MyDrive/noah/Flood\")\n",
        "flood_dirs = [\"5yr\", \"25yr\", \"100yr\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "5Qa3d3nRAhE6",
        "outputId": "88895068-0e5a-49a9-a252-d7e570d733b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Merging 5yr...\n",
            "Progress: 1/65\n",
            "Unzipping IlocosNorte.zip...\n",
            "Reading IlocosNorte.zip...\n",
            "Deleting IlocosNorte.zip artifacts...\n",
            "========\n",
            "Progress: 2/65\n",
            "Unzipping LaUnion.zip...\n",
            "Reading LaUnion.zip...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-3878f3629978>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmap_to_city\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_TO_FLOOD_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflood_dirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-fb3454b16413>\u001b[0m in \u001b[0;36mmap_to_city\u001b[0;34m(path_to_dir, dirs)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mdissolve_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"geometry\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mtemp_gdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mzip_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mgdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_gdf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fiona\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         return _read_file_fiona(\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36m_read_file_fiona\u001b[0;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m                 )\n\u001b[1;32m    359\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m                 df = GeoDataFrame.from_features(\n\u001b[0m\u001b[1;32m    361\u001b[0m                     \u001b[0mf_filt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"geometry\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/geopandas/geodataframe.py\u001b[0m in \u001b[0;36mfrom_features\u001b[0;34m(cls, features, crs, columns)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures_lst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0;31m# load geometry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__geo_interface__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.Iterator.__next__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/fiona/collection.py\u001b[0m in \u001b[0;36mdriver\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mDriverError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unsupported mode: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;34m\"\"\"Returns the name of the proper OGR driver.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "map_to_city(PATH_TO_FLOOD_DIR, flood_dirs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5gS14AQAk11"
      },
      "source": [
        "## Landslide Hazards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "iDes6tcsAo_q"
      },
      "outputs": [],
      "source": [
        "PATH_TO_LANDSLIDE_HAZ_DIR = Path(\"/content/drive/MyDrive/noah/Landslide/\")\n",
        "landslide_haz_dirs = [\"LandslideHazards\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjNl-Lo2A79W"
      },
      "outputs": [],
      "source": [
        "map_to_city(PATH_TO_LANDSLIDE_HAZ_DIR, landslide_haz_dirs)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
